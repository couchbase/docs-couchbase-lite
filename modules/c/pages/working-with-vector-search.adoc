= Working with Vector Search
:page-status: 
:page-edition: Enterprise
:page-aliases: 
ifdef::show_edition[:page-edition: {release}]
ifdef::prerelease[:page-status: {prerelease}]
:page-role:
:description: Use Vector Search with Full Text Search and Query.
:keywords: edge AI api swift ios macos apple vector search generative

[abstract]
{description}

== Use Vector Search

To configure a project to use vector search, follow the xref:c:gs-install.adoc[installation instructions] to add the Vector Search extension.

NOTE: You must install Couchbase Lite to use the Vector Search extension.

== Create a Vector Index

This method shows how you can create a vector index using the Couchbase Lite Vector Search extension.

[source, c]
----

include::c:example$code_snippets/VectorSearch.h[tags=vs-create-custom-config]

----

First, initialize the `config` object with the `VectorIndexConfiguration()` method with the following parameters:

* The expression of the data as a vector.

* The width or `dimensions` of the vector index is set to `3`.

* The amount of `centroids` is set to `100`.
This means that there will be one hundred buckets with a single centroid each that gathers together similar vectors.

You can also alter some optional config settings such as `encoding`.
From there, you can create an index within a given collection, using the previously generated `config` object.

NOTE: The number of vectors, the width or dimensions of the vectors and the training size can incur high CPU and memory costs as the size of each variable increases.
This is because the training vectors have to be resident on the machine.

=== Vector Index Configuration

The table below displays the different configurations you can modify within your `VectorIndexConfiguration()` function.
For more information on specific configurations, see xref:c:vector-search.adoc[Vector Search.]

.Vector Index Configuration Options
[cols ="4*"]
|===
|Configuration Name |Is Required |Default Configuration |Further Information

|Expression
|image:ROOT:yes.png[]
|No default
| A SQL++ expression indicating where to get the vectors. 
A document property for embedded vectors or
`prediction()` to call a registered Predictive model.
|Number of Dimensions
|image:ROOT:yes.png[]
|No default
|2-4096
|Number of Centroids
|image:ROOT:yes.png[]
|No default
|1-64000. The general guideline is an approximate square root of the number of documents
|Distance Metric
|image:ROOT:no.png[]
|Squared Euclidean Distance (euclideanSquared)
a|You can set the following alternates as your Distance Metric:

* cosine (1 - Cosine similarity)

* Euclidean

* dot (negated dot product)

|Encoding
|image:ROOT:no.png[]
| Scalar Quantizer(SQ) or SQ-8 bits
a|There are three possible configurations:

* None
No compression, No data loss
* Scalar Quantizer (SQ) or SQ-8 bits (Default)
Reduces the number of bits per dimension 
* Product Quantizer (PQ)
Reduces the number of dimensions and bits per dimension

|Training Size
|image:ROOT:no.png[]
a|There are defaults for both the minimum and maximum training size for training the vectors

* The minimum training size is set to 25x the number of Centroids or 2 ^PQ's^ ^bits^ when PQ is used

* The maximum training size is set to 256x the number of Centroids or 2 ^PQ's^ ^bits^ when PQ is used
|
|NumProbes
|image:ROOT:no.png[]
|The default value is 0. The number of Probes is calculated based on the number of Centroids
|A guideline for setting a custom number of probes is at least 8 or 0.5% the number of Centroids
|isLazy
|image:ROOT:no.png[]
|False
|Setting the value to true will enable lazy mode for the vector index

|===

CAUTION: Altering the default training sizes could be detrimental to the accuracy of returned results produced by the model and total computation time.

== Generating Vectors

You can use the following methods to generate vectors in Couchbase Lite:

. You can call a Machine Learning(ML) model, and embed the generated vectors inside the documents.

. You can use the `prediction()` function to generate vectors to be indexed for each document at the indexing time.

. You can use Lazy Vector Index (lazy index) to generate vectors asynchronously from remote ML models that may not always be reachable or functioning, skipping or scheduling retries for those specific cases.

Below are example configurations of the previously mentioned methods.

=== Create a Vector Index with Embeddings

This method shows you how to create a Vector Index with embeddings.

[source, c]
----

include::c:example$code_snippets/VectorSearch.h[tags=vs-create-index]

----

. First, create the standard configuration, setting up an expression, number of dimensions and number of centroids for the vector embedding.

. Next, create a vector index, `colors_index`, on a collection and pass it our configuration.

=== Create Vector Index Embeddings from a Predictive Model

This method generates vectors to be indexed for each document at the index time by using the `prediction()` function.
The key difference to note is that the `config` object uses the output of the `prediction()` function as the `expression` parameter to generate the vector index.

[source, c]
----
        
include::c:example$code_snippets/VectorSearch.h[tags=vs-create-predictive-index]

----

NOTE: You can use less storage by using the `prediction()` function as the encoded vectors will only be stored in the index. 
However, the index time will be longer as vector embedding generation is occurring at run time.

== Create a Lazy Vector Index

Lazy indexing is an alternate approach to using the standard predictive model with regular vector indexes which handle the indexing process automatically.
You can use lazy indexing to use a ML model that is not available locally on the device and to create vector indexes without having vector embeddings in the documents.

[source, c]
----

include::c:example$code_snippets/VectorSearch.h[tags=vs-lazy-index-config]

----

You can enable lazy vector indexing by setting the `isLazy` property to `true` in your vector index configuration.

NOTE: Lazy Vector Indexing is opt-in functionality, the `isLazy` property is set to `false` by default.

=== Updating the Lazy Index

Below is an example of how you can update your lazy index.

[source, c]
----

include::c:example$code_snippets/VectorSearch.h[tags=vs-create-lazy-index-embedding]

----

You procedurally update the vectors in the index by looping through the vectors in batches until you reach the value of the `limit` parameter.

The update process follows the following sequence:

. Get a value for the updater.

.. If the there is no value for the vector, handle it. 
In this case, the vector will be skipped and considered the next time `BeginUpdate()` is called.
+
NOTE: A key benefit of lazy indexing is that the indexing process continues if a vector fails to generate.
For standard vector indexing, this will cause the affected documents to be dropped from the indexing process.
+
. Set the vector from the computed vector derived from the updater value and your ML model.

.. If there is no value for the vector, this will result in the underlying document to not be indexed.

. Once all vectors have completed the update loop, finish updating.

NOTE: `CBLIndexUpdater_Release()` will throw an error if any values inside the updater have not been set or skipped.

== Vector Search SQL++ Support

Couchbase Lite currently supports Hybrid Vector Search and the `APPROX_VECTOR_DISTANCE()` function.

IMPORTANT: Similar to the xref:c:fts.adoc[Full Text Search] `match()` function, the `APPROX_VECTOR_DISTANCE()` function and Hybrid Vector Search cannot use the `OR` expression with the other expressions in the related `WHERE` clause.

== Use Hybrid Vector Search

You can use Hybrid Vector Search (Hybrid Search) to perform vector search in conjunction with regular SQL++ queries.
With Hybrid Search, you perform vector search on documents that have already been filtered based on criteria specified in the `WHERE` clause.

NOTE: A `LIMIT` clause is required for non-hybrid Vector Search, this avoids a slow, exhaustive unlimited search of all possible vectors. 

=== Hybrid Vector Search with Full Text Match

Below is an example of using Hybrid Search with the Full Text `match()` function.

[source, c]
----
        
include::c:example$code_snippets/VectorSearch.h[tags=vs-hybrid-ftmatch]

----

=== Prediction with Hybrid Vector Search

Below is an example of using Hybrid Search with an array of vectors generated by the `Prediction()` function at index time.

[source, c]
----
        
include::c:example$code_snippets/VectorSearch.h[tags=vs-hybrid-prediction]

----

== `APPROX_VECTOR_DISTANCE(vector-expr, target-vector, [metric], [nprobes], [accurate])`

WARNING: If you use a different distance metric in the `APPROX_VECTOR_DISTANCE()` function from the one configured in the index, you will receive an error when compiling the query.

[cols = "3*"]
|===
|Parameter |Is Required |Description

|vector-expr
|image:ROOT:yes.png[]
|The expression returning a vector (NOT Index Name).
Must match the expression specified in the vector index exactly.
|target-vector
|image:ROOT:yes.png[]
|The target vector.
|metric
|image:ROOT:no.png[]
|Values : "EUCLIDEAN_SQUARED", “L2_SQUARED”, “EUCLIDEAN”, “L2”,  ”COSINE”, “DOT”.
If not specified, the metric set in the vector index is used.
If specified, the metric must match with the metric set in the vector index.
This optional parameter allows multiple indexes to be attached to the same field in a document. 
|nprobes
|image:ROOT:no.png[]
|Number of buckets to search for the nearby vectors.
If not specified, the nprobes set in the vector index is used. 
|accurate
|image:ROOT:no.png[]
|If not present, false will be used, which means that the quantized/encoded vectors in the index will be used for calculating the distance. 

IMPORTANT: Only accurate = false is supported 

|===

=== Use `APPROX_VECTOR_DISTANCE()`

[source, c]
----
        
include::c:example$code_snippets/VectorSearch.h[tags=vs-apvd-where]

----

This function returns the approximate distance between a given vector, typically generated from your ML model, and an array of vectors with size equal to the `LIMIT` parameter, collected by a SQL++ query using `APPROX_VECTOR_DISTANCE()`.

=== Prediction with `APPROX_VECTOR_DISTANCE()`

Below is an example of using `APPROX_VECTOR_DISTANCE()` with an array of vectors generated by the `Prediction()` function at index time.

[source, c]
----
        
include::c:example$code_snippets/VectorSearch.h[tags=vs-apvd-prediction]

----

== See Also

* xref:c:gs-install.adoc[Installation Instructions]

* xref:c:vector-search.adoc[Vector Search]

* xref:c:fts.adoc[Full Text Search]
