= Vector Search
:page-status: Beta
:page-edition: Enterprise
:page-aliases: 
ifdef::show_edition[:page-edition: {release}]
ifdef::prerelease[:page-status: {prerelease}]
:page-role:
:description: Use Vector Search for AI applications.
:keywords: edge AI api swift ios macos apple vector search generative

[abstract]
{description}

== About Vector Search

You can use Vector Search to find the top N items similar to a given item based on the similarity of their vector representations. 
This is useful for building Generative AI applications.

Vector search is a sophisticated data retrieval technique that focuses on matching the contextual meanings of search queries and data entries, rather than simple text matching.
Vectors are represented by arrays of numbers known as an embedding, which are generated by Large Language Models (LLMs) to represent objects such as text, images, and audio. 

== Applications of Vector Search

You can xref:swift:gs-install.adoc[use Vector Search] to enhance your mobile and edge applications in a variety of use cases, these include:

* Enhance Data Privacy on the Edge - By performing Vector Search within the device, personal data and search queries of a sensitive nature do not have to leave the device

* Provide Low Latency Application Support - By embedding the models within the application or hosting them at an edge data center rather than generating the models from the cloud, you can significantly reduce the round trip time it takes to respond to queries

* Perform Semantic and Similarity Search on the Edge - Any offline-first application that uses Full Text Search will benefit from rich semantic text capabilites offered by Vector Search to retrieve contextually relevant data

* Create recommendation engines - Recommending items with related text strings

* Reduce the Cost Per Query - By embedding the model within the application and handling searches locally, you can reduce data transfer costs and save on bandwidth by avoiding the need to generate embeddings via cloud hosted models.

* Augment user prompts and provide additional context to LLMs with Retrieval Augmented Generation (RAG) - Augment queries by passing user prompts through generating a Vector Embedding representing the query against an existing database, such as an edge data centre. 
This will then return similar vectors to the original query and will then be passed alongside it, augmenting the user prompt with additional related context to be passed to the LLM. 
This results in the LLM returning a result that is likely to be far more contextually relevant than the standalone prompt.

* Enhance the relevance of searches - Ranking results by similarity to given input strings

== About Vector Indexes

Vector Indexes are used to store and manage vector representations of content.
You can use Vector Indexes to efficiently retrieve vectors, similar to a target vector.
Before use, a Vector Index needs to be trained to compute the centroids and parameters for encoding the vectors. 
Training is configured to commence automatically on the first Vector Search query when there are enough vectors to be trained based on the `minimum-training-size` configuration.

== About Vector Embeddings

Vector embeddings represent a Machine Learning (ML) model as an array of numbers to capture semantic or contextual relationships between data points.
This representation encodes how a ML model understands the input or inputs provided to it, based on how the model was initially trained and the internal structure of the model.
When a model considers the features of a given input as similar, the distance between the vector embeddings will be short.
Vector embeddings are stored within embedded vector indexes.

== About Vector Encoding

Vector encoding reduces the size of Vectors index by algorithmic compression.
This compression reduces disk space required and I/O time during indexing and queries, but greater compression can result in inaccurate results in distance calculations.

Vector Search for Couchbase Lite supports the following encoding algorithms:

* None - This will return the highest quality results but at high performance and disk space costs

* Scalar Quantizer - This reduces the number of bits used for each number in a vector. 
The number of bits per component can be set to 4, 6, or 8 bits.
The default setting in Couchbase Lite is 8 bits Scalar Quantizer or SQ-8.

* Product Quantizer - This reduces the number of dimensions and bits per dimension. 
It splits the vectors into multiple subspaces and performing scalar quantization on each space independently before compression.
This can produce higher quality results than Scalar Quantization at the cost of greater complexity.

NOTE: Quantizers are algorithmic processes that map input values from a larger set to output values in a smaller set, common quantization processes can include operations such as rounding and truncation.

== About Centroids

Centroids are vectors that function as the center point of a vector cluster within the training data set.
Each vector is then associated to the vector it is closest to by https://en.wikipedia.org/wiki/K-means_clustering[k-means clustering.]
Each Centroid is contained within a bucket along with its associated vectors.

== About Dimensions

Vector dimensions describes the amount of numbers in a given vector embedding, commonly known as its' width.
The greater the amount of dimensions, the greater accuracy of results, this also results in greater compute and memory costs and a increase in the latency of the search. 

== About Distance Metrics

Distance metrics are a form of index used for Vector Search to define how close an input query vector is to other vectors within a vector index.

Couchbase Lite supports two forms of distance metrics:

* Squared Euclidean Distance - This measures the straight-line distance between two points in Euclidean space which is defined by n dimensions, such as x,y,z.
This metric focuses on the spatial separation or distance between two vectors.
Both the magnitude and direction of the vectors matter.
The smaller the distance value, the more similar the vectors are.
This is the default distance metric.

* Cosine Distance - This measures the cosine of the angle between two vectors in vector space.
This metric focuses on the alignment of two vectors, the similarity of direction.
Only the direction of the vectors matter.
The smaller the distance value, the more similar the vectors are.

== See Also

* xref:swift:gs-install.adoc[Install Couchbase Lite and Vector Search]

* xref:swift:vector-search-api-reference.adoc[Vector Search API Reference]

* xref:swift:working-with-vector-search.adoc[Working with Vector Search]

* xref:swift:fts.adoc[Full Text Search]